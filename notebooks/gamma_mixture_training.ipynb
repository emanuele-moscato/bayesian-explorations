{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399939cc-285f-4a67-a420-adad18069c73",
   "metadata": {},
   "source": [
    "# Training distributions (Gamma mixtures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0e171-508c-4ac4-8ce9-66820cfee1f0",
   "metadata": {},
   "source": [
    "__WARNING__\n",
    "\n",
    "This notebook contains experiments with TFP's distributions which are __not__ guaranteed to be the right way to approach the problem. There can be bugs in the code and mistakes in the logic. The solution is built sequentially with multiple attempts and some attempts do contain mistakes that are addressed in the following attempts: they are marked and left there for instructional purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80692120-9cf8-4245-a007-b06875e40d99",
   "metadata": {},
   "source": [
    "__Problem__\n",
    "\n",
    "Suppose there's a system that check if you forgot to lock the door of your house when you left it, and in case you left it unlocked it sends a message on your phone: you may or may not see it and if you see it you may or may not read it. In case you haven't read it after five minutes, the system sends you a reminder. We have data about the people who read the message, containing how much time (in minutes) it took people to read it and we want to model its probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839acfb9-c3c7-4fb2-805e-43228ff49db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223094ae-f5e4-4c2a-b187-8a81f32c23f5",
   "metadata": {},
   "source": [
    "## A first look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1122374-cae0-4b66-bd45-a92de5fea7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_deltas = tf.constant(np.load('../data/gamma_mixture/time_deltas.npy'))\n",
    "\n",
    "time_deltas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73804a93-af20-4a43-b259-c1c8b4d16a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    x=time_deltas.numpy(),\n",
    "    stat='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd1452-c800-4c9a-87c1-c445715fb2a3",
   "metadata": {},
   "source": [
    "## Modelling the distribution of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ed4df-3850-42af-8c8b-f8d67230b245",
   "metadata": {},
   "source": [
    "### Fit a Gamma distribution directly (\"by hand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f794341-6f1d-41ce-94e5-57083816a91f",
   "metadata": {},
   "source": [
    "Suppose the data comes from a single Gamma distribution. We can use the analytical form of the maximum likelihood estimates of its parameter to compute the \"maximum likelihood\" fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79754561-fe74-468b-8e6d-f9e38cf7f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gamma_estimates(data):\n",
    "    \"\"\"\n",
    "    Given some data assumed to be distributed according to a Gamma, computes\n",
    "    the maximum likelihood estimates for the parameters of the distribution.\n",
    "    Formulas are taken from: https://en.wikipedia.org/wiki/Gamma_distribution#Maximum_likelihood_estimation\n",
    "    \"\"\"\n",
    "    n_samples = tf.cast(data.shape[0], tf.float64)\n",
    "    \n",
    "    sum_x = tf.reduce_sum(data)\n",
    "    sum_log_x = tf.reduce_sum(tf.math.log(data))\n",
    "    sum_x_log_x = tf.reduce_sum(tf.math.log(data) * data)\n",
    "    \n",
    "    denom = (n_samples * sum_x_log_x - sum_log_x * sum_x)\n",
    "    \n",
    "    alpha_hat = n_samples * sum_x / denom\n",
    "    beta_hat = (tf.math.square(n_samples)) / denom\n",
    "    \n",
    "    return alpha_hat, beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f024a-c30d-4a22-bbd6-30588db2e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_hat, beta_hat = get_gamma_estimates(time_deltas)\n",
    "\n",
    "gamma_fit = tfd.Gamma(\n",
    "    concentration=alpha_hat,\n",
    "    rate=beta_hat)\n",
    "\n",
    "gamma_fit.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0ec14-a4e6-4269-b1c5-90662d84bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    time_deltas.numpy(),\n",
    "    stat='density',\n",
    "    label='Data')\n",
    "\n",
    "x_values = tf.linspace(1e-6, 10., 1000).numpy()\n",
    "\n",
    "plt.plot(\n",
    "    x_values,\n",
    "    gamma_fit.prob(x_values),\n",
    "    color='orange',\n",
    "    label='Gamma distribution fit')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4edec-bf4c-40bc-a30a-9f87d378d4ef",
   "metadata": {},
   "source": [
    "Observation: this is definitely not the way to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8fea20-8c9b-4f79-b753-e14f4df6d803",
   "metadata": {},
   "source": [
    "### Training TFP distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed802a2-bc0e-48ed-86a6-6476e55f0a82",
   "metadata": {},
   "source": [
    "TFP distributions are trainable: their parameters can be opimized (e.g. via gradient descent) as if they were parameters of a model. This can be used to fit distributions to our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681ae90-a34c-4978-942c-4e3b0dcfbc88",
   "metadata": {},
   "source": [
    "#### A single Gamma distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a20c2f-755b-4168-a0ab-a4de8bcba359",
   "metadata": {},
   "source": [
    "The distribution of the data appears to have a bump right after 5 minutes, consistent with the fact that some people read the message after they receive the reminder. This tells us that if we want to try to fit a single Gamma distribution to the data we should drop this bump, so we drop all the time deltas greater than 5 (minutes).\n",
    "\n",
    "Note: in doing so we also drop the tail of the Gamma distribution we're trying to fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f3614-5e22-418a-b878-91c5362b35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(distr, data):\n",
    "    \"\"\"\n",
    "    Negative log likelihood loss.\n",
    "    \"\"\"\n",
    "    return - tf.reduce_sum(distr.log_prob(data))\n",
    "\n",
    "\n",
    "def train_distr(distr, data, epochs, loss_fn, lr=0.05):\n",
    "    \"\"\"\n",
    "    Explicit implementation of gradient descent.\n",
    "    \"\"\"\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=0.05)\n",
    "    \n",
    "    loss_history = []\n",
    "    params_history = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(distr.trainable_variables)\n",
    "            \n",
    "            loss = loss_fn(distr, data)\n",
    "        \n",
    "        gradient = g.gradient(loss, distr.trainable_variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradient, distr.trainable_variables))\n",
    "        \n",
    "        loss_history.append(loss_fn(distr, data))\n",
    "        params_history.append(distr.trainable_variables)\n",
    "        \n",
    "        if (i % 100) == 0:\n",
    "            print(f'Epoch: {i+1} of {epochs} | Loss: {loss_history[-1]}')\n",
    "        \n",
    "    print(f'Epoch: {i+1} of {epochs} | Loss: {loss_history[-1]}')\n",
    "        \n",
    "    return loss_history, params_history, distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f1d16-332f-475c-8062-d9f797021904",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.cast(time_deltas[time_deltas < 5.], tf.float32)\n",
    "\n",
    "# Rescale data so it starts from 0.\n",
    "data = data - tf.reduce_min(data) + 10e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec9941f-e9ce-4de7-8e3b-2e866ccff866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values for the gradient descent.\n",
    "one_gamma_concentration = tf.Variable(3., name='one_gamma_concentration', dtype=tf.float32)\n",
    "one_gamma_rate = tf.Variable(3., name='one_gamma_rate', dtype=tf.float32)\n",
    "\n",
    "one_gamma = tfd.Gamma(\n",
    "    concentration=one_gamma_concentration,\n",
    "    rate=one_gamma_rate)\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "loss_history, params_history, one_gamma_trained = train_distr(one_gamma, data, epochs, get_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8839c7-5533-4107-b224-fabd3a29c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_gamma_trained.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4193730-e6a1-4810-96fd-0233329dd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.histplot(\n",
    "    data.numpy(),\n",
    "    stat='density',\n",
    "    label='data')\n",
    "\n",
    "x_values = tf.linspace(1e-6, 10., 1000).numpy()\n",
    "\n",
    "plt.plot(\n",
    "    x_values,\n",
    "    one_gamma_trained.prob(x_values),\n",
    "    color='orange')\n",
    "\n",
    "sns.histplot(\n",
    "    one_gamma_trained.sample(10000),\n",
    "    stat='density',\n",
    "    color='orange',\n",
    "    label='Fit')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc4e4f-2a57-425b-a55a-4f2b75bfaccc",
   "metadata": {},
   "source": [
    "Observation: not a very good fit, but after all we cut away the tail of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738fc3f-8213-42d2-848f-abd927ad093f",
   "metadata": {},
   "source": [
    "#### A mixture of Gamma distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe07481c-1c71-4b7f-908d-dc7bb72807e2",
   "metadata": {},
   "source": [
    "Let's now try to keep all the data (including the second peak) and fit a mixture of Gamma distributions to it, one representing the first peak and one representing the second. Now we have two pairs of parameters for the two distributions, plus the parameters for the mixture.\n",
    "\n",
    "Note: __mistake!__ The parameters of the mixture are probabilities themselves, so each should be in $[0, 1]$ and they should add up to one. This is a constraint that should be imposed during the optimization, otherwise it's not guaranteed that we end up with sensible results (and by the way this is also true for the parameters of the Gammas, which may end up outside of their allowed domain!). We're keeping this error here because we'll correct it later in more refined attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0bf64-e975-4319-ab87-c183451c4c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.cast(time_deltas, tf.float64)\n",
    "\n",
    "# Rescale data so it starts from 0 (modulo a small offset to avoid log(0) when\n",
    "# computing the log likelihood).\n",
    "data = data - tf.reduce_min(data) + 10e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5779c-52f2-48b8-b9dc-153a78af0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values for the gradient descent.\n",
    "mixture_probs = tf.Variable([0.7, 0.3], dtype=tf.float64)\n",
    "mixture_concentrations = tf.Variable([3., 12.], dtype=tf.float64)\n",
    "mixture_rates = tf.Variable([3., 3.], dtype=tf.float64)\n",
    "\n",
    "# MixtureSameFamily allows to build a mixture of distribution provided they\n",
    "# are the same distribution (in terms of functional form) with different\n",
    "# values for the parameters.\n",
    "mixture_distr = tfd.MixtureSameFamily(\n",
    "    # A categorical distribution is used to take a mixture of the component\n",
    "    # distributions.\n",
    "    mixture_distribution=tfd.Categorical(\n",
    "        probs=mixture_probs),\n",
    "    components_distribution=tfd.Gamma(\n",
    "      concentration=mixture_concentrations,\n",
    "      rate=mixture_rates)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a4230-f6b7-4b20-9973-44acfefae585",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, params_history, mixture_distr_trained = train_distr(mixture_distr, data, 5000, get_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7c987-cd3e-474f-9d74-db02d167bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mixture_distr_trained.parameters['mixture_distribution'].parameters)\n",
    "print(mixture_distr_trained.parameters['components_distribution'].parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e1499-bec9-4a4b-8391-62bc39e2e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    data.numpy(),\n",
    "    stat='density',\n",
    "    label='Data')\n",
    "\n",
    "sns.histplot(\n",
    "    mixture_distr_trained.sample(100000),\n",
    "    stat='density',\n",
    "    color='orange',\n",
    "    label='Samples from the trained distribution')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "# Plot each component.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    data.numpy(),\n",
    "    stat='density',\n",
    "    label='Data',\n",
    "    color=sns.color_palette()[0])\n",
    "\n",
    "sns.histplot(\n",
    "    mixture_distr_trained.parameters['components_distribution'][0].sample(100000),\n",
    "    stat='density',\n",
    "    color='orange',\n",
    "    label='Mixture first component')\n",
    "\n",
    "sns.histplot(\n",
    "    mixture_distr_trained.parameters['components_distribution'][1].sample(100000),\n",
    "    stat='density',\n",
    "    color=sns.color_palette()[2],\n",
    "    label='Mixture second component')\n",
    "\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df41c2e-8f56-4b93-919a-601d44d705a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_distr_trained.parameters['mixture_distribution'].parameters['probs'].numpy().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a7151-2e0b-466e-a3b1-82d5f709c8bd",
   "metadata": {},
   "source": [
    "Observation: we evidently made some mistakes here,\n",
    "- As mentioned above, we didn't impose any constraints on the parameters we're optimizing, and indeed the above line shows exaclty that.\n",
    "- Because we used a mixture of two \"copies\" of the same distribution, the two components ended up overlapping a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737890d4-0f5a-4be9-a709-155ac641cdc1",
   "metadata": {},
   "source": [
    "#### A mixture of a Gamma distributions and a shifted Gamma distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ec355-8377-4c78-99bc-b7989f1de8f1",
   "metadata": {},
   "source": [
    "Consider an alternative system that doesn't send any reminder. In this case we'd expect the bump visible after 5 minutes to disappear and we'd model the distribution of the data with a single Gamma distribution.\n",
    "\n",
    "In the real case the bump at 5 minutes could be modeled as another Gamma \"starting\" at 5 minutes, so we end up with a mixture of a Gamma (with domain $[0, +\\infty)$) and a Gamma shifted forward by 5 (with domain $[5, +\\infty)$). In this attempt, the shift is taken as another parameter to optimize (even though we know it should be 5 minutes).\n",
    "\n",
    "Note: __mistake!__ We're still not addressing the issue of imposing the constraints on the parameters during the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3124d20-ccc0-4a3b-a5c6-c4958bf8f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side note: test shifting a distribution with the Shift bijector.\n",
    "gamma_test = tfd.Gamma(\n",
    "      concentration=tf.constant(3., dtype=tf.float64),\n",
    "      rate=tf.constant(3., dtype=tf.float64))\n",
    "\n",
    "# TFP implements transformation on distributions as bijector objects.\n",
    "shift = tfp.bijectors.Shift(tf.constant(-3, dtype=tf.float64))\n",
    "\n",
    "# TransformedDistribution allows to obtain the desired result by combining\n",
    "# the original distribution with the appropriate bijector.\n",
    "gamma_test_shifted = tfd.TransformedDistribution(\n",
    "    gamma_test,\n",
    "    shift)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    gamma_test.sample(100000),\n",
    "    stat='density',\n",
    "    label='Original distribution')\n",
    "\n",
    "sns.histplot(\n",
    "    gamma_test_shifted.sample(100000),\n",
    "    stat='density',\n",
    "    color='orange',\n",
    "    label='Shifted distribution')\n",
    "\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3563fbc-366b-49c8-9bf9-bbc4c7b3b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.cast(time_deltas, tf.float64)\n",
    "\n",
    "# Rescale data so it starts from 0 (modulo a small offset to avoid log(0) when\n",
    "# computing the log likelihood).\n",
    "data = data - tf.reduce_min(data) + 10e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8fa15-7a83-48c0-ae90-0fdee69d4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_probs = tf.Variable([0.9, 0.1], dtype=tf.float64)\n",
    "\n",
    "gamma_1_concentration = tf.Variable(1.5, dtype=tf.float64)\n",
    "gamma_1_rate = tf.Variable(1., dtype=tf.float64)\n",
    "gamma_2_concentration = tf.Variable(3., dtype=tf.float64)\n",
    "gamma_2_rate = tf.Variable(10., dtype=tf.float64)\n",
    "gamma_2_shift = tf.Variable(5. - 10e-10, dtype=tf.float64)\n",
    "# gamma_1_concentration = tf.Variable(3., dtype=tf.float64)\n",
    "# gamma_1_rate = tf.Variable(3., dtype=tf.float64)\n",
    "# gamma_2_concentration = tf.Variable(30., dtype=tf.float64)\n",
    "# gamma_2_rate = tf.Variable(3., dtype=tf.float64)\n",
    "# gamma_2_shift = tf.Variable(5. - 10e-10, dtype=tf.float64)\n",
    "\n",
    "\n",
    "mixture_distr = tfd.Mixture(\n",
    "    cat=tfd.Categorical(\n",
    "        probs=mixture_probs),\n",
    "    components=[\n",
    "        tfd.Gamma(\n",
    "            concentration=gamma_1_concentration,\n",
    "            rate=gamma_1_rate,\n",
    "            name='Gamma'),\n",
    "        tfd.TransformedDistribution(\n",
    "            tfd.Gamma(\n",
    "                concentration=gamma_2_concentration,\n",
    "                rate=gamma_2_rate),\n",
    "            tfp.bijectors.Shift(gamma_2_shift),\n",
    "            name='shiftGamma')\n",
    "    ]\n",
    ") \n",
    "\n",
    "\n",
    "# Plot samples from the mixture distribution with initial values.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    data.numpy(),\n",
    "    stat='density',\n",
    "    label='Data')\n",
    "\n",
    "sns.histplot(\n",
    "    mixture_distr.sample(100000),\n",
    "    stat='density',\n",
    "    color='orange',\n",
    "    label='Samples from the distribution (initial values for the parameters)')\n",
    "\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46e668-02c1-4d24-84f0-01c57fd15ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way, training is hopeless.\n",
    "loss_history, params_history, mixture_distr_trained = train_distr(mixture_distr, data, 1, get_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872621c-e839-4fa2-9c19-0f59b7e41f03",
   "metadata": {},
   "source": [
    "Observation: we immediatly got a null value for the loss function!\n",
    "\n",
    "__Explanation:__ we know have a mixture of two distributions, one defined in $[0, +\\infty)$ and the other in $[5, +\\infty)$. The loss function we're using is the negative log likelihood, but there's a problem here: according to mixture models, each data point is generated by any of the components of the mixture with a certain probability, so its contribution to the log likelihood will be (the logarithm of) a linear combination of its probability according to each component. But for points lying between 0 and the shift parameter (the \"beginning\" of the second Gamma), the second Gamma cannot be evaluated because they're outside of its domain.\n",
    "\n",
    "__Solution:__ if we want to use a mixture with a shifted Gamma we also need to correct the loss function so that the negative log likelihood is computed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8409941-b063-4edf-ab8c-957936627423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of the above issue.\n",
    "# Datapoints x s.t. x > 5 generate sensible log likelihood.\n",
    "print(mixture_distr.log_prob(data[data >= gamma_2_shift]))\n",
    "\n",
    "# For datapoints x s.t. x < 5 the log likelihood can't be computedf\n",
    "print(mixture_distr.log_prob(data[data < gamma_2_shift]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ef390-1ce7-4a35-a0fb-fba78762d73e",
   "metadata": {},
   "source": [
    "#### A mixture of a Gamma distributions and a shifted Gamma distribution, fixing the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a62d6-8d03-4697-87bc-41e4af8479eb",
   "metadata": {},
   "source": [
    "Not only will we fix the Gamma, but we'll also experiment constraining the optimization of the parameters of the mixture and having a variable or fixed shift parameter. Use the various variables/constants for different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6cfeea-a6dc-4583-b08d-8f98f20b4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_loss_shifted_mixture(mixture_distr, data):\n",
    "    \"\"\"\n",
    "    Negative log likelihood loss, fixed for the mixture distribution of a\n",
    "    Gamma and a shifted Gamma.\n",
    "    \"\"\"\n",
    "    # Get the shift parameter.\n",
    "    shift_param = mixture_distr.parameters['components'][1].parameters['bijector'].shift\n",
    "    \n",
    "    # For all the datapoints in [0, shift_param], the contribution to the log\n",
    "    # likelihood is given only by the first Gamma in the distribution.\n",
    "    ll_below_shift = tf.reduce_sum(mixture_distr.parameters['components'][0].log_prob(data[data < shift_param]))\n",
    "    \n",
    "    # For all the datapoints in [shift_param, +oo], the contribution to the\n",
    "    # log likelihood is given by the full mixture.\n",
    "    ll_above_shift = tf.reduce_sum(mixture_distr.log_prob(data[data >= shift_param]))\n",
    "\n",
    "    return - (ll_below_shift + ll_above_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a956cfc-b189-4a88-981d-7610f48dc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.cast(time_deltas, tf.float64)\n",
    "\n",
    "# Rescale data so it starts from 0 (modulo a small offset to avoid log(0) when\n",
    "# computing the log likelihood.\n",
    "data = data - tf.reduce_min(data) + 10e-12\n",
    "\n",
    "# Ignore the last part of the tail (probably outliers).\n",
    "data = data[data < 10.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c15ea-7c7d-400a-8fbf-8a2ccba2b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters (constant and/or variable, experimenting).\n",
    "cat_probs = tf.Variable(\n",
    "    [0.8, 0.2],\n",
    "    name='cat_probs',\n",
    "    dtype=tf.float64,\n",
    "    # Constrain cat_probs[0] to be in [0, 1] (or smaller, to avoid extreme\n",
    "    # values) and cat_probs[1] to be 1 - cat_probs[0].\n",
    "    constraint=(lambda cat_probs: tf.Variable([\n",
    "        tf.clip_by_value(cat_probs[0], 0.8 + 10e-10, 1. - 10e-10),\n",
    "        1. - tf.clip_by_value(cat_probs[0], 0.8 + 10e-10, 1. - 10e-10)]))\n",
    ")\n",
    "cat_probs_const = tf.constant(\n",
    "    [0.9, 0.1],\n",
    "    name='cat_probs',\n",
    "    dtype=tf.float64)\n",
    "\n",
    "gamma_1_concentration = tf.Variable(1.5, dtype=tf.float64, name='gamma_1_concentration')\n",
    "gamma_1_rate = tf.Variable(1., dtype=tf.float64, name='gamma_1_rate')\n",
    "\n",
    "gamma_2_concentration = tf.Variable(3., dtype=tf.float64, name='gamma_2_concentration')\n",
    "gamma_2_rate = tf.Variable(10., dtype=tf.float64, name='gamma_2_rate')\n",
    "\n",
    "gamma_2_shift = tf.Variable(\n",
    "    5. - 10e-10,\n",
    "    dtype=tf.float64,\n",
    "    name='gamma_2_shift',\n",
    "    # What if we constrain the shift parameter so it doesn't move towards 0?\n",
    "    # constraint=lambda s: tf.clip_by_value(s, 4.7, 99.)\n",
    ")\n",
    "gamma_2_shift_const = tf.constant(\n",
    "    5. - 10e-10,\n",
    "    dtype=tf.float64,\n",
    "    name='gamma_2_shift')\n",
    "\n",
    "\n",
    "# Define the mixture model.\n",
    "mixture_distr = tfd.Mixture(\n",
    "    cat=tfd.Categorical(\n",
    "        probs=cat_probs),\n",
    "    components=[\n",
    "        tfd.Gamma(\n",
    "            concentration=gamma_1_concentration,\n",
    "            rate=gamma_1_rate,\n",
    "            name='Gamma'),\n",
    "        tfd.TransformedDistribution(\n",
    "            tfd.Gamma(\n",
    "                concentration=gamma_2_concentration,\n",
    "                rate=gamma_2_rate),\n",
    "            tfp.bijectors.Shift(gamma_2_shift_const),\n",
    "            name='shiftGamma')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Plot samples from the mixture distribution with initial values.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    data.numpy(),\n",
    "    stat='density',\n",
    "    label='Data')\n",
    "\n",
    "sns.histplot(\n",
    "    mixture_distr.sample(100000),\n",
    "    stat='density',\n",
    "    color='orange',\n",
    "    label='Samples from the distribution (initial values for the parameters)')\n",
    "\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31c4ae-51b5-4f66-893c-01d03df6bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_distr.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cb75c-d375-427e-b39d-feffbde91078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "loss_history, params_history, mixture_distr_trained = train_distr(\n",
    "    mixture_distr,\n",
    "    data,\n",
    "    1000,\n",
    "    get_loss_shifted_mixture,\n",
    "    lr=0.9)\n",
    "\n",
    "# Plot!\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    data.numpy(),\n",
    "    stat='density',\n",
    "    label='Data')\n",
    "\n",
    "sns.histplot(\n",
    "    mixture_distr.sample(100000),\n",
    "    stat='density',\n",
    "    color='orange',\n",
    "    label='Samples from the trained distribution')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "# Plot each component separately (without the weights from the mixture).\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.histplot(\n",
    "    data.numpy(),\n",
    "    stat='density',\n",
    "    label='Data',\n",
    "    color=sns.color_palette()[0])\n",
    "\n",
    "sns.histplot(\n",
    "    mixture_distr.parameters['components'][0].sample(100000),\n",
    "    stat='density',\n",
    "    color='orange',\n",
    "    label='Mixture first component')\n",
    "\n",
    "sns.histplot(\n",
    "    mixture_distr.parameters['components'][1].sample(100000),\n",
    "    stat='density',\n",
    "    color=sns.color_palette()[2],\n",
    "    label='Mixture second (shifted) component')\n",
    "\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d7d1c-afc6-46b1-8e24-35375f047124",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_distr_trained.parameters['cat'].parameters['probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2090d4a4-8729-45e4-a74b-c388d3c66947",
   "metadata": {},
   "source": [
    "Observation: keeping the weights in the mixture as variables to optimize but having a constant shift for the shifted Gamma we get something that, if not perfect, is at least sensible! Notice however that the mixture weights haven't moved from the original value - which signals that there might be something wrong with how the constraints were enforced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f72111-0751-436c-9b89-0e0ee8140bee",
   "metadata": {},
   "source": [
    "#### Further ideas\n",
    "\n",
    "- Try different component distributions (log-normal, exponential, ...).\n",
    "- Try different combination of trainable and fixed parameters.\n",
    "- Try different initial values for the trainable parameters.\n",
    "- Try more epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
