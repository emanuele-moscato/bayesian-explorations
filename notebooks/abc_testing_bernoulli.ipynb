{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0372b681-e618-4e7a-88a5-cf16f7b0d764",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A/B/C testing with Bernoulli trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47d5f1-bb7d-4706-ab49-0e307eb27880",
   "metadata": {},
   "source": [
    "A small example on Bayesian A/B/C testing with Bernoulli trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346315dc-0010-42c8-93be-e1a82638a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.fftpack import next_fast_len\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import arviz as az\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "sns.set_theme()\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0286d08-2aaa-4568-8a68-cbb627cb49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_stuff(states, previous_kernel_results):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # I couldn't find a way not to make the counter global.\n",
    "    step = next(counter)\n",
    "    \n",
    "    if (step % 100) == 0:\n",
    "        print(f\"Step {step}, state: {states}\")\n",
    "    \n",
    "    return previous_kernel_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab64a3e-7c02-4e16-9779-13ca9d4dc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data taken from the contingency table - please double check!\n",
    "data_no_action = tf.concat([tf.ones(320), tf.zeros(1015)], axis=0)\n",
    "data_free_delivery = tf.concat([tf.ones(1288), tf.zeros(3205)], axis=0)\n",
    "data_no_discount = tf.concat([tf.ones(1198), tf.zeros(3235)], axis=0)\n",
    "\n",
    "data_no_action.shape, data_free_delivery.shape, data_no_discount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0444682-31f2-4a32-851e-3b05f35e7320",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8509ca-482c-4873-b9ef-31de4f0e8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First possibility: define a joint distribution object that behaves well with\n",
    "# varying parameter shapes.\n",
    "joint_distr_no_action = tfd.JointDistributionSequential([\n",
    "    tfd.Uniform(low=0., high=1.),\n",
    "    lambda p: tfd.Independent(\n",
    "        tfd.Bernoulli(\n",
    "            probs=tf.expand_dims(p, -1) * tf.ones_like(data_no_action)\n",
    "        ),\n",
    "        reinterpreted_batch_ndims=1\n",
    "    )\n",
    "])\n",
    "\n",
    "joint_distr_free_delivery = tfd.JointDistributionSequential([\n",
    "    tfd.Uniform(low=0., high=1.),\n",
    "    lambda p: tfd.Independent(\n",
    "        tfd.Bernoulli(\n",
    "            probs=tf.expand_dims(p, -1) * tf.ones_like(data_free_delivery)\n",
    "        ),\n",
    "        reinterpreted_batch_ndims=1\n",
    "    )\n",
    "])\n",
    "\n",
    "joint_distr_no_discount = tfd.JointDistributionSequential([\n",
    "    tfd.Uniform(low=0., high=1.),\n",
    "    lambda p: tfd.Independent(\n",
    "        tfd.Bernoulli(\n",
    "            probs=tf.expand_dims(p, -1) * tf.ones_like(data_no_discount)\n",
    "        ),\n",
    "        reinterpreted_batch_ndims=1\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1f7cc-48a7-467d-b908-0e574d21b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target log prob function in the two cases. Comment/uncomment to select which\n",
    "# one to use.\n",
    "# Using a joint distribution object.\n",
    "unnormalized_posterior_log_prob_combined = lambda p_control, p_treatment, p_treatment_2: (\n",
    "    joint_distr_no_action.log_prob(p_control, data_no_action)\n",
    "    + joint_distr_free_delivery.log_prob(p_treatment, data_free_delivery)\n",
    "    + joint_distr_no_discount.log_prob(p_treatment_2, data_no_discount)\n",
    ")\n",
    "\n",
    "# # Test if the unnormalized posterior log prob behaves as expected with a\n",
    "# possible initial state as the input.\n",
    "state_batch = [\n",
    "    tf.stack([\n",
    "        tf.reduce_mean(tf.cast(data_no_action, tf.float32)),\n",
    "    ] * n_chains),\n",
    "    tf.stack([\n",
    "        tf.reduce_mean(tf.cast(data_free_delivery, tf.float32)),\n",
    "    ] * n_chains),\n",
    "    tf.stack([\n",
    "        tf.reduce_mean(tf.cast(data_no_discount, tf.float32)),\n",
    "    ] * n_chains)\n",
    "]\n",
    "\n",
    "unnormalized_posterior_log_prob_combined(*state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429e06f-d52e-4375-badf-2a7f4fd7b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_steps = 2000\n",
    "burnin = 500\n",
    "leapfrog_steps=2\n",
    "\n",
    "# Set the chain's start state.\n",
    "initial_chain_state = [\n",
    "    tf.stack([\n",
    "        tf.reduce_mean(tf.cast(data_no_action, tf.float32)),\n",
    "    ] * n_chains),\n",
    "    tf.stack([\n",
    "        tf.reduce_mean(tf.cast(data_free_delivery, tf.float32)),\n",
    "    ] * n_chains),\n",
    "    tf.stack([\n",
    "        tf.reduce_mean(tf.cast(data_no_discount, tf.float32)),\n",
    "    ] * n_chains)\n",
    "]\n",
    "\n",
    "# Since HMC operates over unconstrained space, we need to transform the\n",
    "# samples so they live in real-space.\n",
    "unconstraining_bijectors = [\n",
    "    tfp.bijectors.Sigmoid(),  # Maps R to (0, 1).\n",
    "    tfp.bijectors.Sigmoid(),   # Maps R to (0, 1).\n",
    "    tfp.bijectors.Sigmoid()   # Maps R to (0, 1).\n",
    "]\n",
    "\n",
    "step_size = tf.Variable(0.5, dtype=tf.float32)\n",
    "\n",
    "# Defining the HMC\n",
    "hmc = tfp.mcmc.TransformedTransitionKernel(\n",
    "    inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        # target_log_prob_fn=unnormalized_posterior_log_prob_control,\n",
    "        target_log_prob_fn=unnormalized_posterior_log_prob_combined,\n",
    "        num_leapfrog_steps=leapfrog_steps,\n",
    "        step_size=step_size,\n",
    "        # The step size adaptation prevents stationarity to occur, so the\n",
    "        # number of adaptation steps should be smaller than the number of\n",
    "        # burnin steps so that in the remaining part of the burnin phase\n",
    "        # stationarity can be reached.\n",
    "        step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(num_adaptation_steps=int(burnin * 0.8)),\n",
    "        state_gradients_are_stopped=True),\n",
    "    bijector=unconstraining_bijectors)\n",
    "\n",
    "# Sampling from the chain.\n",
    "print('Sampling started')\n",
    "\n",
    "counter = itertools.count(1)\n",
    "\n",
    "[\n",
    "    posterior_prob_no_action,\n",
    "    posterior_prob_free_delivery,\n",
    "    posterior_prob_no_discount\n",
    "], kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=number_of_steps + burnin,\n",
    "    num_burnin_steps=burnin,\n",
    "    current_state=initial_chain_state,\n",
    "    kernel=hmc,\n",
    "    trace_fn=trace_stuff)\n",
    "\n",
    "print('Sampling finished')\n",
    "\n",
    "trace_no_action_combined_burned = posterior_prob_no_action[burnin:]\n",
    "trace_free_delivery_combined_burned = posterior_prob_free_delivery[burnin:]\n",
    "trace_no_discount_combined_burned = posterior_prob_no_discount[burnin:]\n",
    "\n",
    "inference_data = az.convert_to_inference_data({\n",
    "    'p_no_action': tf.transpose(trace_no_action_combined_burned),\n",
    "    'p_free_delivery': tf.transpose(trace_free_delivery_combined_burned),\n",
    "    'p_no_discount': tf.transpose(trace_no_discount_combined_burned)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7edd65-6125-49dc-a20b-143b8841446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f10603-7228-47e4-b94b-7e8d2814050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f61d9-3c9b-414b-9bc8-d19f7b3e9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(inference_data)\n",
    "\n",
    "az.plot_autocorr(inference_data)\n",
    "\n",
    "az.plot_posterior(inference_data)\n",
    "\n",
    "az.plot_forest(inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42d4e9-f3b7-4211-8cf1-6be9d8845931",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_no_action_flattened = tf.reshape(\n",
    "    trace_no_action_combined_burned,\n",
    "    shape=(trace_no_action_combined_burned.shape[0] * trace_no_action_combined_burned.shape[1])\n",
    ")\n",
    "\n",
    "trace_free_delivery_flattened = tf.reshape(\n",
    "    trace_free_delivery_combined_burned,\n",
    "    shape=(trace_free_delivery_combined_burned.shape[0] * trace_free_delivery_combined_burned.shape[1])\n",
    ")\n",
    "\n",
    "trace_no_discount_flattened = tf.reshape(\n",
    "    trace_no_discount_combined_burned,\n",
    "    shape=(trace_no_discount_combined_burned.shape[0] * trace_no_discount_combined_burned.shape[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a62f9a-27d6-49e1-8cdb-4098125122fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_free_delivery_flattened.numpy().mean(), trace_free_delivery_flattened.numpy().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195a315-62d8-47d3-af62-f546fc43c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_no_discount_flattened.numpy().mean(), trace_no_discount_flattened.numpy().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22277f41-16b8-4d2d-bac6-9bda9877e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_free_delivery.numpy().mean(), data_no_discount.numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca8664-ec57-4778-981d-f0ba13ff9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Estimated probability that the no discount group returns more than the no action group:',\n",
    "    (trace_no_discount_flattened > trace_no_action_flattened).numpy().mean()\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Estimated probability that the free delivery group returns more than the no action group:',\n",
    "    (trace_free_delivery_flattened > trace_no_action_flattened).numpy().mean()\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Estimated probability that the free delivery group returns more than the no discount group:',\n",
    "    (trace_free_delivery_flattened > trace_no_discount_flattened).numpy().mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556febc-7b21-4132-8b27-b76910c0cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.histplot(\n",
    "    x=trace_no_action_flattened.numpy(),\n",
    "    label=f'No action (est. mean: {trace_no_action_flattened.numpy().mean()})',\n",
    "    color=sns.color_palette()[0],\n",
    "    stat='density',\n",
    "    kde=True)\n",
    "sns.histplot(\n",
    "    x=trace_free_delivery_flattened.numpy(),\n",
    "    label=f'Free delivery (est. mean: {trace_free_delivery_flattened.numpy().mean()})',\n",
    "    color=sns.color_palette()[1],\n",
    "    stat='density',\n",
    "    kde=True)\n",
    "sns.histplot(\n",
    "    x=trace_no_discount_flattened.numpy(),\n",
    "    label=f'No discount (est. mean: {trace_no_discount_flattened.numpy().mean()})',\n",
    "    color=sns.color_palette()[2],\n",
    "    stat='density',\n",
    "    kde=True)\n",
    "\n",
    "plt.axvline(\n",
    "    x=trace_no_action_flattened.numpy().mean(),\n",
    "    ymin=0.,\n",
    "    ymax=1.,\n",
    "    color=sns.color_palette()[0]\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    x=trace_free_delivery_flattened.numpy().mean(),\n",
    "    ymin=0.,\n",
    "    ymax=1.,\n",
    "    color=sns.color_palette()[1]\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    x=trace_no_discount_flattened.numpy().mean(),\n",
    "    ymin=0.,\n",
    "    ymax=1.,\n",
    "    color=sns.color_palette()[2]\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Rate of returning customers by CRM action', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
