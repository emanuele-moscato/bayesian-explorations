{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3adfebc4-b9b8-44d0-bc80-4b1e4068008f",
   "metadata": {},
   "source": [
    "# Autoencoders for images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926ce68-bdc5-4832-b1a0-c1a5e0fd3dba",
   "metadata": {},
   "source": [
    "__Objective:__ understand how to encode images in a 2-dimensional latent space via an autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30b2b4-3c52-4b16-8eb6-9ceb5415049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('../../modules/')\n",
    "\n",
    "from autoencoders import Encoder, Decoder\n",
    "from keras_utilities import append_to_full_history, plot_history, get_intermediate_output\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cec19d-4111-45b4-82eb-a3352bbebc1a",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae9476-dcf9-4a6e-9712-4aba0653575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(img):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Normalize pixel values.\n",
    "    img = img.astype('float32') / 255.\n",
    "\n",
    "    # Add padding.\n",
    "    img = np.pad(img, ((0, 0), (2, 2), (2, 2)), constant_values=0.)\n",
    "    \n",
    "    # The images come in grayscale without an explicit\n",
    "    # channels dimensions. Here we add it.\n",
    "    img = np.expand_dims(img, -1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a6f59-d776-4c5f-867d-07ae61262d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we don't really care about the labels in the y arrays.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b5fa5-f9a7-49de-8e59-17dc4eb6a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14, 6))\n",
    "\n",
    "for i in range(len(axs)):\n",
    "    axs[i].imshow(\n",
    "        x_train[i, ...],\n",
    "        cmap='gray'\n",
    "    )\n",
    "    \n",
    "    axs[i].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29897cf2-4f12-40a7-8528-235ba8904fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_images(x_train)\n",
    "x_test = preprocess_images(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0f37e-6b67-4435-95b4-31c87571da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14, 6))\n",
    "\n",
    "for i in range(len(axs)):\n",
    "    axs[i].imshow(\n",
    "        x_train[i, ...],\n",
    "        cmap='gray'\n",
    "    )\n",
    "    \n",
    "    axs[i].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322004fa-7ffc-4f01-bd29-619855b91e56",
   "metadata": {},
   "source": [
    "## Autoencoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f8b47-374b-4e3e-b174-fd0964ba3103",
   "metadata": {},
   "source": [
    "Model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47221db3-ff9c-4773-8d56-4b660cf1e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "\n",
    "encoder(x_train[:10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b47f9-2bd3-412d-b528-cb9a722d13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last image-like shape (rank-3 tensor) before the flattening\n",
    "# layer in the encoder.\n",
    "image_reshaping_size = tuple(get_intermediate_output(x_train[:1, ...], encoder, 3).shape[1:])\n",
    "\n",
    "decoder = Decoder(image_reshaping_size)\n",
    "\n",
    "decoder(encoder(x_train[:2, ...])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c039877-2036-409b-9a5a-c27d6238f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_input = tf.keras.Input(shape=x_train[0, ...].shape)\n",
    "\n",
    "autoencoder_model = tf.keras.Model(\n",
    "    inputs=autoencoder_input,\n",
    "    outputs=decoder(encoder(autoencoder_input))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcad6d1-a9e1-40a9-8076-0219a3e91b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model(x_train[:10, ...]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16da50-e340-44b1-8f6b-e443c08eed21",
   "metadata": {},
   "source": [
    "Model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b656f-96e3-49fd-8b97-0963e9a5c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "full_history = dict([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac82030-bff4-4538-bf21-d35ec4dfcd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "history = autoencoder_model.fit(\n",
    "    x=x_train,\n",
    "    y=x_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test)\n",
    ")\n",
    "\n",
    "append_to_full_history(history, full_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef64b8-d2af-4627-aef5-ffe8ec364685",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(full_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a6b75-c122-4f53-a517-0ca7fb888bda",
   "metadata": {},
   "source": [
    "## Image reconstruction after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7654f6-ae78-4b63-a67c-e8cf74d18c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 6\n",
    "\n",
    "reconstructed_images = tf.concat(\n",
    "    [\n",
    "        x_test[:ncols, ...][None, ...],\n",
    "        autoencoder_model(x_test[:ncols, ...])[None, ...]\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 4))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        ax.imshow(\n",
    "            reconstructed_images[i, j, ...],\n",
    "            cmap='gray'\n",
    "        )\n",
    "\n",
    "        ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcf90b-ccfa-4156-876e-3c313d28acb4",
   "metadata": {},
   "source": [
    "## Exploration of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07a517-69c3-4178-8911-657b06300fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "\n",
    "latent_vectors = encoder(x_test[:n_samples, ...])\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=latent_vectors[:, 0],\n",
    "    y=latent_vectors[:, 1],\n",
    "    hue=y_test[:n_samples],\n",
    "    palette=sns.color_palette()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e25b8-eed4-4b74-97ee-f6d6cd3f3b3d",
   "metadata": {},
   "source": [
    "## Generating new images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048ae06-8eed-45c1-ac4c-95e95d3f2f6d",
   "metadata": {},
   "source": [
    "**Idea:** we randomly sample the latent space and have the decoder produce an image from the new latent vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403cb891-3ddb-4fe1-b837-ca3643c29c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 6\n",
    "\n",
    "# Bounds (along each dimension of the latent space)\n",
    "# of the region of latent space we want to randomly\n",
    "# sample from (a rectangle).\n",
    "bounds = ((-5., 0.), (-5., 10.))\n",
    "\n",
    "# Random 2-dimensional vectors in the chose region\n",
    "# in latent space.\n",
    "random_latent_vectors = tf.concat(\n",
    "    [\n",
    "        tf.random.uniform(shape=(n_samples, 1), minval=bounds[0][0], maxval=bounds[0][1]),\n",
    "        tf.random.uniform(shape=(n_samples, 1), minval=bounds[1][0], maxval=bounds[1][1])\n",
    "    ],\n",
    "    axis=-1\n",
    ")\n",
    "\n",
    "# Decode the randomly-generated latent vectors into\n",
    "# images via the decoder.\n",
    "random_images = decoder(random_latent_vectors)\n",
    "\n",
    "\n",
    "# Plot the position of the random latent vectors over\n",
    "# existing samples.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=latent_vectors[:, 0],\n",
    "    y=latent_vectors[:, 1],\n",
    "    color=sns.color_palette()[0],\n",
    "    alpha=.3\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=random_latent_vectors[:, 0],\n",
    "    y=random_latent_vectors[:, 1],\n",
    "    color=sns.color_palette()[3],\n",
    ")\n",
    "\n",
    "\n",
    "# Show the decoded images corresponding to the random\n",
    "# latent vectors.\n",
    "fig, axs = plt.subplots(ncols=n_samples, figsize=(14, 4))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    axs[i].imshow(\n",
    "        random_images[i, ...],\n",
    "        cmap='gray'\n",
    "    )\n",
    "\n",
    "    axs[i].grid(False)\n",
    "\n",
    "    plt.sca(axs[i])\n",
    "    plt.title(f'{random_latent_vectors[i, ...].numpy().round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d420eb05-6938-4de0-8429-0931395252e3",
   "metadata": {},
   "source": [
    "Consider a path (straight line) in latent space and generate samples going along it to see how they change. This should generate some kind of morphing between the images corresponding to the initial and final points, but nothing guarantees that it will be continuous nor that all the generated images will be realistic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1c155-b38f-404e-84d2-0c5d496acd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate path in latent space.\n",
    "n_points = 20\n",
    "\n",
    "starting_point = tf.constant([-5., -2.5])\n",
    "endpoint = tf.constant([-2.5, 2.5])\n",
    "\n",
    "path = (endpoint - starting_point) * tf.linspace(0., 1., n_points)[..., None] + starting_point\n",
    "\n",
    "# Generate images correponding to points along\n",
    "# the path.\n",
    "images_along_path = decoder(path)\n",
    "\n",
    "# Plot generated images.\n",
    "ncols = 10\n",
    "nrows = n_points // ncols\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 4))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        ax.imshow(\n",
    "            images_along_path[i * ncols + j, ...],\n",
    "            cmap='gray'\n",
    "        )\n",
    "\n",
    "        ax.grid(False)\n",
    "\n",
    "        plt.sca(ax)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f'{path[i * ncols + j, ...].numpy().round(2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
