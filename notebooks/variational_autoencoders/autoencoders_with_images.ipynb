{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3adfebc4-b9b8-44d0-bc80-4b1e4068008f",
   "metadata": {},
   "source": [
    "# Autoencoders for images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926ce68-bdc5-4832-b1a0-c1a5e0fd3dba",
   "metadata": {},
   "source": [
    "__Objective:__ understand how to encode images in a 2-dimensional latent space via an autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30b2b4-3c52-4b16-8eb6-9ceb5415049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('../../modules/')\n",
    "\n",
    "from keras_utilities import append_to_full_history, plot_history\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cec19d-4111-45b4-82eb-a3352bbebc1a",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae9476-dcf9-4a6e-9712-4aba0653575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(img):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Normalize pixel values.\n",
    "    img = img.astype('float32') / 255.\n",
    "\n",
    "    # Add padding.\n",
    "    img = np.pad(img, ((0, 0), (2, 2), (2, 2)), constant_values=0.)\n",
    "    \n",
    "    # The images come in grayscale without an explicit\n",
    "    # channels dimensions. Here we add it.\n",
    "    img = np.expand_dims(img, -1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a6f59-d776-4c5f-867d-07ae61262d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we don't really care about the labels in the y arrays.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b5fa5-f9a7-49de-8e59-17dc4eb6a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14, 6))\n",
    "\n",
    "for i in range(len(axs)):\n",
    "    axs[i].imshow(\n",
    "        x_train[i, ...],\n",
    "        cmap='gray'\n",
    "    )\n",
    "    \n",
    "    axs[i].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29897cf2-4f12-40a7-8528-235ba8904fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_images(x_train)\n",
    "x_test = preprocess_images(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0f37e-6b67-4435-95b4-31c87571da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14, 6))\n",
    "\n",
    "for i in range(len(axs)):\n",
    "    axs[i].imshow(\n",
    "        x_train[i, ...],\n",
    "        cmap='gray'\n",
    "    )\n",
    "    \n",
    "    axs[i].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322004fa-7ffc-4f01-bd29-619855b91e56",
   "metadata": {},
   "source": [
    "## Dutoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa96fa9-8086-4821-9f67-7ccf15c5b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intermediate_output(x, model, n_layers):\n",
    "    \"\"\"\n",
    "    Given the NN `model`, passes the input `x` through\n",
    "    it first `n_layers` layers and outputs the result.\n",
    "    \"\"\"\n",
    "    output = x\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        output = model.layers[i](output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f8b47-374b-4e3e-b174-fd0964ba3103",
   "metadata": {},
   "source": [
    "Model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189e237-51cc-4674-b58f-1b1740f05ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Sequence of number of filters (for the corresponding\n",
    "        # convolutional layers in the stack).\n",
    "        self.filters_list = [32, 64, 128]\n",
    "\n",
    "        # Input placeholder. Actually not needed if defining\n",
    "        # the model this way.\n",
    "        self.model_input = Input(shape=(32, 32, 1))\n",
    "\n",
    "        # Stack of convolutional layers.\n",
    "        self.conv_layers = [\n",
    "            Conv2D(\n",
    "                filters=filters,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=2,\n",
    "                activation='relu',\n",
    "                padding='same'\n",
    "            )\n",
    "            for filters in self.filters_list\n",
    "        ]\n",
    "\n",
    "        # Flattening layer to reshape the image into a rank-1\n",
    "        # tensor.\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        # Final dense layer, projecting the intermediate outputs\n",
    "        # to the 2-dimensional latent space.\n",
    "        self.final_dense = Dense(units=2)\n",
    "\n",
    "    def call(self, x):\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = conv_layer(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.final_dense(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, image_reshaping_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial dense layer: maps latent vectors into\n",
    "        # vectors with enough components to be reshaped\n",
    "        # into images.\n",
    "        self.initial_dense = Dense(\n",
    "            units=np.prod(image_reshaping_size)\n",
    "        )\n",
    "\n",
    "        # Reshapes a rank-1 vector into a rank-3 tensor\n",
    "        # representing an image.\n",
    "        self.reshape = Reshape(image_reshaping_size)\n",
    "\n",
    "        # List of numbers filters to be used by the stack of\n",
    "        # transposed convolutional layers. The length of the list\n",
    "        # corresponds to the number of layers in the stack.\n",
    "        self.filters_list = [128, 64, 32]\n",
    "\n",
    "        # Stack of transposed convolutional layers.\n",
    "        self.conv_transp_layers = [\n",
    "            Conv2DTranspose(\n",
    "                filters=filters,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=2,\n",
    "                activation='relu',\n",
    "                padding='same'\n",
    "            )\n",
    "            for filters in self.filters_list\n",
    "        ]\n",
    "\n",
    "        # Final convolutional layer, outputting a tensor with\n",
    "        # the right shape, one channel dimension (grayscale)\n",
    "        # and pixel intensities normalized in [0, 1] (sigmoid\n",
    "        # activation).\n",
    "        self.final_conv = Conv2D(\n",
    "            filters=1,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            activation='sigmoid',\n",
    "            padding='same'\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.initial_dense(x)\n",
    "        x = self.reshape(x)\n",
    "\n",
    "        for conv_t_layer in self.conv_transp_layers:\n",
    "            x = conv_t_layer(x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47221db3-ff9c-4773-8d56-4b660cf1e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "\n",
    "encoder(x_train[:10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b47f9-2bd3-412d-b528-cb9a722d13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last image-like shape (rank-3 tensor) before the flattening\n",
    "# layer in the encoder.\n",
    "image_reshaping_size = tuple(get_intermediate_output(x_train[:1, ...], encoder, 3).shape[1:])\n",
    "\n",
    "decoder = Decoder(image_reshaping_size)\n",
    "\n",
    "decoder(encoder(x_train[:2, ...])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c039877-2036-409b-9a5a-c27d6238f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_input = tf.keras.Input(shape=x_train[0, ...].shape)\n",
    "\n",
    "autoencoder_model = tf.keras.Model(\n",
    "    inputs=autoencoder_input,\n",
    "    outputs=decoder(encoder(autoencoder_input))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcad6d1-a9e1-40a9-8076-0219a3e91b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model(x_train[:10, ...]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16da50-e340-44b1-8f6b-e443c08eed21",
   "metadata": {},
   "source": [
    "Model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b656f-96e3-49fd-8b97-0963e9a5c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "full_history = dict([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac82030-bff4-4538-bf21-d35ec4dfcd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "history = autoencoder_model.fit(\n",
    "    x=x_train,\n",
    "    y=x_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test)\n",
    ")\n",
    "\n",
    "append_to_full_history(history, full_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef64b8-d2af-4627-aef5-ffe8ec364685",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(full_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a6b75-c122-4f53-a517-0ca7fb888bda",
   "metadata": {},
   "source": [
    "## Image reconstruction after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7654f6-ae78-4b63-a67c-e8cf74d18c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 6\n",
    "\n",
    "reconstructed_images = tf.concat(\n",
    "    [\n",
    "        x_test[:ncols, ...][None, ...],\n",
    "        autoencoder_model(x_test[:ncols, ...])[None, ...]\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 4))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        ax.imshow(\n",
    "            reconstructed_images[i, j, ...],\n",
    "            cmap='gray'\n",
    "        )\n",
    "\n",
    "        ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcf90b-ccfa-4156-876e-3c313d28acb4",
   "metadata": {},
   "source": [
    "## Exploration of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de4fe6-3b76-4304-80bb-ba1ea69c980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07a517-69c3-4178-8911-657b06300fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "\n",
    "latent_vectors = encoder(x_test[:n_samples, ...])\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=latent_vectors[:, 0],\n",
    "    y=latent_vectors[:, 1],\n",
    "    hue=y_test[:n_samples],\n",
    "    palette=sns.color_palette()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e25b8-eed4-4b74-97ee-f6d6cd3f3b3d",
   "metadata": {},
   "source": [
    "## Generating new images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048ae06-8eed-45c1-ac4c-95e95d3f2f6d",
   "metadata": {},
   "source": [
    "**Idea:** we randomly sample the latent space and have the decoder produce an image from the new latent vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403cb891-3ddb-4fe1-b837-ca3643c29c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 6\n",
    "\n",
    "# Bounds (along each dimension of the latent space)\n",
    "# of the region of latent space we want to randomly\n",
    "# sample from (a rectangle).\n",
    "bounds = ((-5., 0.), (-5., 10.))\n",
    "\n",
    "# Random 2-dimensional vectors in the chose region\n",
    "# in latent space.\n",
    "random_latent_vectors = tf.concat(\n",
    "    [\n",
    "        tf.random.uniform(shape=(n_samples, 1), minval=bounds[0][0], maxval=bounds[0][1]),\n",
    "        tf.random.uniform(shape=(n_samples, 1), minval=bounds[1][0], maxval=bounds[1][1])\n",
    "    ],\n",
    "    axis=-1\n",
    ")\n",
    "\n",
    "# Decode the randomly-generated latent vectors into\n",
    "# images via the decoder.\n",
    "random_images = decoder(random_latent_vectors)\n",
    "\n",
    "\n",
    "# Plot the position of the random latent vectors over\n",
    "# existing samples.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=latent_vectors[:, 0],\n",
    "    y=latent_vectors[:, 1],\n",
    "    color=sns.color_palette()[0],\n",
    "    alpha=.3\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=random_latent_vectors[:, 0],\n",
    "    y=random_latent_vectors[:, 1],\n",
    "    color=sns.color_palette()[3],\n",
    ")\n",
    "\n",
    "\n",
    "# Show the decoded images corresponding to the random\n",
    "# latent vectors.\n",
    "fig, axs = plt.subplots(ncols=n_samples, figsize=(14, 4))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    axs[i].imshow(\n",
    "        random_images[i, ...],\n",
    "        cmap='gray'\n",
    "    )\n",
    "\n",
    "    axs[i].grid(False)\n",
    "\n",
    "    plt.sca(axs[i])\n",
    "    plt.title(f'{random_latent_vectors[i, ...].numpy().round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d420eb05-6938-4de0-8429-0931395252e3",
   "metadata": {},
   "source": [
    "Consider a path (straight line) in latent space and generate samples going along it to see how they change. This should generate some kind of morphing between the images corresponding to the initial and final points, but nothing guarantees that it will be continuous nor that all the generated images will be realistic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1c155-b38f-404e-84d2-0c5d496acd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate path in latent space.\n",
    "n_points = 20\n",
    "\n",
    "starting_point = tf.constant([-5., -2.5])\n",
    "endpoint = tf.constant([-2.5, 2.5])\n",
    "\n",
    "path = (endpoint - starting_point) * tf.linspace(0., 1., n_points)[..., None] + starting_point\n",
    "\n",
    "# Generate images correponding to points along\n",
    "# the path.\n",
    "images_along_path = decoder(path)\n",
    "\n",
    "# Plot generated images.\n",
    "ncols = 10\n",
    "nrows = n_points // ncols\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 4))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        ax.imshow(\n",
    "            images_along_path[i * ncols + j, ...],\n",
    "            cmap='gray'\n",
    "        )\n",
    "\n",
    "        ax.grid(False)\n",
    "\n",
    "        plt.sca(ax)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f'{path[i * ncols + j, ...].numpy().round(2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
