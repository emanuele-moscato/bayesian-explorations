{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b243e51-f5de-4d02-8210-0850e7d3e240",
   "metadata": {},
   "source": [
    "# Variational autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef28c2-467b-4e4b-981f-ec5d98eb327a",
   "metadata": {},
   "source": [
    "__Objective:__ define a variational autoencoder for images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77a635-1d45-4631-b6a2-b59c44ad7a8b",
   "metadata": {},
   "source": [
    "**Idea:** in an autoencoder, the encoder maps samples to points in latent space. In a variational autoencoder, it maps samples to **multivariate Gaussian distributions** on latent space. This helps reconstructing similar samples from nearby points in latent space, because the decoder now needs to minimize the reconstruction error for all the points sampled from the distribution corresponding to the same input sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802441d-cd23-42ce-821f-5fc4b4da1aec",
   "metadata": {},
   "source": [
    "### Ingredients\n",
    "\n",
    "#### Encoder\n",
    "\n",
    "the encoder part of the model is modified to output the parameters for a multivariate Gaussian on latent space with diagonal covariance matrix. In practice, given the input sample $x$, the encoder outputs two vectors $\\mu(x), \\sigma(x) \\in \\mathbb{R}^d$, where $d$ is the dimension of latent space, parametrizing a distribution $\\mathcal{N}(\\mu(x), \\Sigma(x))$, where $\\Sigma(x) = \\mathrm{diag}(\\sigma^2_1(x), \\ldots, \\sigma^2_d(x))$.\n",
    "\n",
    "#### Decoder\n",
    "\n",
    "latent vectors $z\\in \\mathbb{R}^d$ are obtained by sampling the distributions on latent space, and given a latent vector the decoder produces a realistic sample, as similar as possible to the one correspnding to the Gaussian distribution that generated $z$. The architecture of the decoder indeed remains the same as in regular autoencoders.\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "The loss function to minimize has an additional term w.r.t. the usual MSE or categorical cross-entropy consisting in the KL divergence of the Gaussian distribution on the latent space corresponding to each sample and a (multivariate) standard normal distribution,\n",
    "$$\n",
    "\\mathrm{KL}\\left[ \\mathcal{N}(\\mu(x), \\Sigma(x)) || \\mathcal{N}(0, \\mathbf{1}) \\right]\\,.\n",
    "$$\n",
    "This comes from assuming a multivariate standard normal prior on latent space, a Gaussian likelihood and an approximate variational posterior given by the multivariate Gaussian outputted by the encoder. With the reparametrization trick, the loss function is then given by the KL-divergence of the variational posterior and the true posterior (product of likelihood and prior).\n",
    "\n",
    "The KL divergence above can be computed analytically, so given $\\mu(x)$ and $\\sigma(x)$ it's easy to compute the exact contribution to the total loss:\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\mathrm{KL}\\left[ \\mathcal{N}(\\mu(x), \\Sigma(x)) || \\mathcal{N}(0, \\mathbf{1}) \\right] &\\equiv& -\\int \\mathrm{d}^d z\\, \\mathcal{N}(z | \\mu(x), \\sigma(x))\\,\\log\\left( \\frac{\\mathcal{N}(z | 0, \\mathbf{1})}{\\mathcal{N}(z | \\mu(x), \\sigma(x))} \\right) \\\\\n",
    "&=& -\\frac{1}{2} \\sum_{j=1}^d \\left( 1 + \\log(\\sigma^2_j) - \\mu_j^2 - \\sigma_j^2 \\right)\\,.\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In the $\\beta$-VAE variant of the model it's possible to tune the relative weight of the reconstruction and KL terms in the loss functions via a coefficient $\\beta$,\n",
    "$$\n",
    "\\mathcal{L} = \\mathrm{MSE} + \\beta\\,\\mathrm{KL}\\,.\n",
    "$$\n",
    "$\\beta$ is an hyperparameter controlling the balance between the minimization of either term in the loss: if $\\beta$ is too small the KL term will have little effect (latent vectors more spread in latent space, farther away from the origin and with discontinuoous clusters), while if $\\beta$ is too big the KL term will prevail and the model will have a poor recontruction power (essentially the Gaussians will end up fitting the unit ones).\n",
    "\n",
    "#### Reparametrization trick\n",
    "\n",
    "Given an input sample, the prediction has a random component corresponding to the sampling of the Gaussian distribution obtained from the input sample via the encoder. Backpropagation would require to \"differentiate the sampling\" w.r.t. the parameters of the Gaussian distribution, which is not possible: one drawn, a sample is a numerical value and all the information about the distribution from which it was generated is lost. Nonetheless, it's possible use a reparametrization of the Gaussian distribution that allows for explicit differentiation w.r.t. to the $\\mu(x)$ and $\\sigma(x)$ parameters, the **reparametrization trick**.\n",
    "\n",
    "Given the input sample $x$, the encoder outputs the parameters $\\mu(x)$ and $\\sigma(x)$ of the multivariate Gaussian $\\mathcal{N}(\\mu(x), \\sigma(x))$, from which the latent vector $z$ is sampled,\n",
    "$$\n",
    "z \\sim \\mathcal{N}(\\mu(x), \\sigma(x))\\,.\n",
    "$$\n",
    "The reparametrization trick consists in sampling $z$ in the equivalent way\n",
    "$$\n",
    "z = \\mu(x) + \\sigma(x)\\,\\epsilon\\,,\n",
    "$$\n",
    "where $\\epsilon \\sim \\mathcal{N}(0, 1)$. This way the generated values for $z$ are exactly equivalent as before, but the parameters $\\mu$ and $\\sigma$ appear exlicitly and differentiation w.r.t. them is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f9fe2-b44d-4f7f-bcbd-bd177f9fb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('../../modules/')\n",
    "\n",
    "from variational_autoencoders import VariationalEncoder, VAE\n",
    "from autoencoders import Decoder\n",
    "from keras_utilities import get_intermediate_output, append_to_full_history, plot_history\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a76995c-93e1-4aa9-8cbe-b7ec5e1a654b",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ad0b5-6170-4aa9-b832-079d77707f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(img):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Normalize pixel values.\n",
    "    img = img.astype('float32') / 255.\n",
    "\n",
    "    # Add padding.\n",
    "    img = np.pad(img, ((0, 0), (2, 2), (2, 2)), constant_values=0.)\n",
    "    \n",
    "    # The images come in grayscale without an explicit\n",
    "    # channels dimensions. Here we add it.\n",
    "    img = np.expand_dims(img, -1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476925a-3eac-4505-b1df-cbd803396302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we don't really care about the labels in the y arrays.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f930a-15a1-424c-9709-2539b67a2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_images(x_train)\n",
    "x_test = preprocess_images(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e364aa-6b96-49a9-82cb-2d913e3382d0",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e2063-9916-4dc3-9af3-38d364d4f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_encoder = VariationalEncoder()\n",
    "\n",
    "n_samples = 5000\n",
    "\n",
    "random_inputs = tf.random.normal(shape=(n_samples, 32, 32, 1))\n",
    "\n",
    "z_mean, z_log_var, z_samples = variational_encoder(random_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5fdac-52c6-4d16-88c9-fad8f6c4e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_encoder = VariationalEncoder()\n",
    "\n",
    "image_reshaping_size = get_intermediate_output(\n",
    "    tf.random.normal(shape=(15, 32, 32, 1)),\n",
    "    variational_encoder,\n",
    "    3\n",
    ").shape[1:]\n",
    "\n",
    "decoder = Decoder(image_reshaping_size)\n",
    "\n",
    "vae_model = VAE(\n",
    "    variational_encoder=variational_encoder,\n",
    "    decoder=decoder\n",
    ")\n",
    "\n",
    "vae_model(tf.random.normal(shape=(21, 32, 32, 1)))\n",
    "\n",
    "vae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b86a9-17d2-4743-b708-3705aaa5d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.compile(\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "full_history = dict([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a4dfc-c27c-49ab-aaa3-c8f2a461ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "history = vae_model.fit(\n",
    "    x_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_test, x_test)\n",
    ")\n",
    "\n",
    "append_to_full_history(history, full_history)\n",
    "\n",
    "plot_history(full_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9220ab6-6c47-47a2-bd3b-265bca7158bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = '../../models/variational_autoencoders/vae_model.keras'\n",
    "\n",
    "vae_model.save(saved_model_path)\n",
    "\n",
    "# loaded_model = tf.keras.models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacec7f9-2518-47a9-b460-9483fcc56893",
   "metadata": {},
   "source": [
    "## Image reconstruction after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201117c9-0121-4869-8ea4-a988037012a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 6\n",
    "\n",
    "reconstructed_images = tf.concat(\n",
    "    [\n",
    "        x_test[:ncols, ...][None, ...],\n",
    "        vae_model(x_test[:ncols, ...])[2][None, ...]\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 4))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        ax.imshow(\n",
    "            reconstructed_images[i, j, ...],\n",
    "            cmap='gray'\n",
    "        )\n",
    "\n",
    "        ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960656f9-6695-4bc7-b6b8-f5cfb4ee5eef",
   "metadata": {},
   "source": [
    "## Exploration of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07a64d-3c19-4c38-9a00-b332e77bf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "\n",
    "z_means, _, z_samples = variational_encoder(x_test[:n_samples, ...])\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=z_means[:, 0],\n",
    "    y=z_means[:, 1],\n",
    "    hue=y_test[:n_samples],\n",
    "    palette=sns.color_palette()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b01809-24db-4751-8717-683c6c2ec6cf",
   "metadata": {},
   "source": [
    "## Generating new images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d478baa-40b0-4e43-9d54-166a639f00e8",
   "metadata": {},
   "source": [
    "Thanks to the KL divergence term in the loss function, the distribution in which samples are encoded should not be too far away from a standard normal distribution. This implies that if we want to generate random samples from latent space, we can just use a standard normal distribution and be to find realistic recostructed samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afac296-05b7-4498-94c6-f2d2bdf5c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 6\n",
    "\n",
    "# Random 2-dimensional vectors in latent space.\n",
    "random_latent_vectors = tf.concat(\n",
    "    [\n",
    "        tf.random.normal(shape=(n_images, 1)),\n",
    "        tf.random.normal(shape=(n_images, 1))\n",
    "    ],\n",
    "    axis=-1\n",
    ")\n",
    "\n",
    "# Decode the randomly-generated latent vectors into\n",
    "# images via the decoder.\n",
    "random_images = vae_model.decoder(random_latent_vectors)\n",
    "\n",
    "\n",
    "# Plot the position of the random latent vectors over\n",
    "# existing samples.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=z_means[:, 0],\n",
    "    y=z_means[:, 1],\n",
    "    color=sns.color_palette()[0],\n",
    "    alpha=.3\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=random_latent_vectors[:, 0],\n",
    "    y=random_latent_vectors[:, 1],\n",
    "    color=sns.color_palette()[3],\n",
    ")\n",
    "\n",
    "\n",
    "# Show the decoded images corresponding to the random\n",
    "# latent vectors.\n",
    "fig, axs = plt.subplots(ncols=n_images, figsize=(14, 4))\n",
    "\n",
    "for i in range(n_images):\n",
    "    axs[i].imshow(\n",
    "        random_images[i, ...],\n",
    "        cmap='gray'\n",
    "    )\n",
    "\n",
    "    axs[i].grid(False)\n",
    "\n",
    "    plt.sca(axs[i])\n",
    "    plt.title(f'{random_latent_vectors[i, ...].numpy().round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178a076-88b9-4fda-a4fc-66d4dc23b3ff",
   "metadata": {},
   "source": [
    "Build a path in latent space and observe the morphing of the corresponding reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d77af2-1c87-4aae-96dc-c2499767d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_point = tf.constant([.8, 0.5])\n",
    "endpoint = tf.constant([2.5, 1.5])\n",
    "\n",
    "n_points = 20\n",
    "\n",
    "path = (endpoint - starting_point) * tf.linspace(0., 1., n_points)[..., None] + starting_point\n",
    "\n",
    "reconstructed_images_path = vae_model.decoder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d86a91-55e7-4b0a-9922-5bd6a184e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=z_means[:, 0],\n",
    "    y=z_means[:, 1],\n",
    "    hue=y_test[:n_samples],\n",
    "    palette=sns.color_palette()\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    x=path[:, 0],\n",
    "    y=path[:, 1],\n",
    "    color=sns.color_palette()[3],\n",
    "    linestyle='dashdot',\n",
    "    linewidth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ac045-b59c-432a-ae90-2d54025f183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images correponding to points along\n",
    "# the path.\n",
    "images_along_path = decoder(path)\n",
    "\n",
    "# Plot generated images.\n",
    "ncols = 10\n",
    "nrows = n_points // ncols\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 4))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        ax.imshow(\n",
    "            images_along_path[i * ncols + j, ...],\n",
    "            cmap='gray'\n",
    "        )\n",
    "\n",
    "        ax.grid(False)\n",
    "\n",
    "        plt.sca(ax)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f'{path[i * ncols + j, ...].numpy().round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da9b93f-feb7-47af-a617-20de658d6cce",
   "metadata": {},
   "source": [
    "## Morphing towards a particular item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15f1c7-97e6-41a5-a55e-c350a2f87e50",
   "metadata": {},
   "source": [
    "Let's say that we want to start from a point in latent space and move along a straight line to morph the reconstructed object into a pair of trousers (class label 1 in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5b703-718b-43dc-890f-1da1b3771b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trousers_samples = x_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f36c4-6279-4bfd-8f60-62bf458bd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 6\n",
    "\n",
    "random_trousers_samples = tf.gather(\n",
    "    trousers_samples,\n",
    "    indices=np.random.choice(range(trousers_samples.shape[0]), ncols)\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=ncols, figsize=(14, 4))\n",
    "\n",
    "for i in range(ncols):\n",
    "    ax = axs[i]\n",
    "    \n",
    "    ax.imshow(\n",
    "        x_test[y_test == 1][i, ...],\n",
    "        cmap='gray'\n",
    "    )\n",
    "\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b781ec3a-cc5a-46cf-80f0-01b6bcd2e088",
   "metadata": {},
   "source": [
    "In order to move in the direction of \"trousers\", we do the following:\n",
    "1. Compute the average latent vector (i.e. mean of the corresponding Gaussians) for all (training) samples belonging to the class.\n",
    "2. Compute the average latent vector for all the (training) samples belonging to any other class.\n",
    "3. Subtract the second from the first and normalize it. This is the general \"trousers\" direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3d52c-addc-49e0-8762-14dd3cbb86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_latent_trousers = tf.reduce_mean(\n",
    "    vae_model.variational_encoder(trousers_samples)[0],\n",
    "    axis=0\n",
    ")\n",
    "average_latent_other_classes = tf.reduce_mean(\n",
    "    vae_model.variational_encoder(x_train[y_train != 1, ...])[0],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "latent_direction_trousers = average_latent_trousers - average_latent_other_classes\n",
    "latent_direction_trousers = latent_direction_trousers / tf.norm(latent_direction_trousers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85540db6-6cf8-487f-94db-92955663c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_direction_trousers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4437480-8edc-4fce-aea2-3684a99c5b12",
   "metadata": {},
   "source": [
    "Let's start from a random point in latent space and let's make the corresponding reconstructed image more \"trousers-y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50580026-3682-4a8f-b19e-053d3cef31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latent_vectors = tf.random.normal(shape=(1, 2))\n",
    "\n",
    "t_path = random_latent_vectors + latent_direction_trousers * tf.linspace(0., 3., 20)[..., None]\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=z_means[:, 0],\n",
    "    y=z_means[:, 1],\n",
    "    hue=y_test[:n_samples],\n",
    "    palette=sns.color_palette()\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    x=t_path[:, 0],\n",
    "    y=t_path[:, 1],\n",
    "    color=sns.color_palette()[3],\n",
    "    linestyle='dashdot',\n",
    "    linewidth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ba7f8-db7f-449c-8813-2bc14d4bedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images correponding to points along\n",
    "# the path.\n",
    "t_morphing_images = vae_model.decoder(t_path)\n",
    "\n",
    "# Plot generated images.\n",
    "ncols = 10\n",
    "nrows = n_points // ncols\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 4))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        ax.imshow(\n",
    "            t_morphing_images[i * ncols + j, ...],\n",
    "            cmap='gray'\n",
    "        )\n",
    "\n",
    "        ax.grid(False)\n",
    "\n",
    "        plt.sca(ax)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f'{t_path[i * ncols + j, ...].numpy().round(2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
